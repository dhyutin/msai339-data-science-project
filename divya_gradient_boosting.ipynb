{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting in Machine Learning\n",
    "\n",
    "## What is Boosting?\n",
    "Boosting is an **ensemble learning technique** that builds a strong learner by combining the predictions of multiple **weak learners** (typically decision trees). The idea is to **improve model performance** iteratively by focusing on correcting the errors made by the previous models.\n",
    "\n",
    "### Key Concepts:\n",
    "1. Boosting trains weak learners sequentially.\n",
    "2. Each weak learner is trained to **minimize the errors** of the previous model.\n",
    "3. Data points that are difficult to predict are given **higher importance** in subsequent iterations.\n",
    "\n",
    "---\n",
    "\n",
    "## Types of Boosting\n",
    "There are several types of boosting algorithms, each with its own methodology for combining weak learners. The most popular ones are:\n",
    "\n",
    "### 1. **AdaBoost (Adaptive Boosting)**\n",
    "- Adjusts the **weights** of data points based on their classification difficulty.\n",
    "- Misclassified points are given **higher weights** so that subsequent models focus on them.\n",
    "- Combines weak learners using a **weighted voting mechanism**.\n",
    "\n",
    "### 2. **Gradient Boosting**\n",
    "- Focuses on **optimizing a loss function** using gradients.\n",
    "- Subsequent models are trained to predict the **residual errors** of the previous model.\n",
    "- Highly customizable and flexible.\n",
    "\n",
    "### 3. **XGBoost**\n",
    "- An optimized implementation of Gradient Boosting.\n",
    "- Features include **regularization**, **tree pruning**, and **parallel processing**, making it faster and more accurate.\n",
    "\n",
    "\n",
    "### 4. **LightGBM**\n",
    "- Another optimized implementation of Gradient Boosting.\n",
    "- Uses **leaf-wise growth** instead of level-wise, which makes it faster and more memory-efficient for large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## Gradient Boosting: In Detail\n",
    "\n",
    "### What is Gradient Boosting?\n",
    "Gradient Boosting is a **specific implementation of Boosting** that uses the **gradient of the loss function** to guide the training process. It combines weak learners (e.g., decision trees) sequentially to reduce errors iteratively.\n",
    "\n",
    "\n",
    "### Advantages of Gradient Boosting:\n",
    "1. **Handles Non-Linear Data**:\n",
    "   - Effectively captures complex patterns in the data.\n",
    "2. **Customizable**:\n",
    "   - Supports different loss functions (e.g., mean squared error, log-loss).\n",
    "3. **Feature Importance**:\n",
    "   - Provides insights into the importance of features.\n",
    "\n",
    "---\n",
    "\n",
    "### Parameters in Gradient Boosting:\n",
    "1. **`n_estimators`**:\n",
    "   - The number of weak learners (trees) to train.\n",
    "   - More trees can lead to better performance but may overfit.\n",
    "2. **`learning_rate`**:\n",
    "   - Controls the contribution of each tree to the final prediction.\n",
    "   - Smaller values (e.g., 0.01) require more trees but improve generalization.\n",
    "3. **`max_depth`**:\n",
    "   - The maximum depth of each tree.\n",
    "   - Limits the complexity of the weak learners to prevent overfitting.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year      hwtsupp  region  statefip  metro  pernum  relate  age  sex  race  \\\n",
      "0  1990  1052.650024       0        36    2.0       1     101   58    1     3   \n",
      "1  2009   971.200012       2         5    2.0       4    1260   28    1     0   \n",
      "2  1990  1622.280029       0        36    3.0       1     101   37    1     0   \n",
      "3  1990  2689.909912       3         6    3.0       1     101   34    1     0   \n",
      "4  1981  1911.900024       2        51    3.0       1     101   38    1     2   \n",
      "\n",
      "   ...  srcearn  hisp  annhrs  incwageman     hrwage   perconexp  hdwfcoh  \\\n",
      "0  ...      1.0     1    1820     14200.0   7.802198   64.639999        1   \n",
      "1  ...      1.0     0    2080     17680.0   8.500000  100.063004        0   \n",
      "2  ...      1.0     0    2080     28000.0  13.461538   64.639999        1   \n",
      "3  ...      1.0     0    2115     27500.0  13.002364   64.639999        1   \n",
      "4  ...      1.0     0    2080     17000.0   8.173077   43.977001        1   \n",
      "\n",
      "   industry  occupation  education  \n",
      "0        10          17          5  \n",
      "1        11          17          5  \n",
      "2         2           4          5  \n",
      "3        14           3          3  \n",
      "4        14           0          5  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344287 entries, 0 to 344286\n",
      "Data columns (total 30 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   year        344287 non-null  int64  \n",
      " 1   hwtsupp     344287 non-null  float64\n",
      " 2   region      344287 non-null  int64  \n",
      " 3   statefip    344287 non-null  int64  \n",
      " 4   metro       344287 non-null  float64\n",
      " 5   pernum      344287 non-null  int64  \n",
      " 6   relate      344287 non-null  int64  \n",
      " 7   age         344287 non-null  int64  \n",
      " 8   sex         344287 non-null  int64  \n",
      " 9   race        344287 non-null  int64  \n",
      " 10  marst       344287 non-null  int64  \n",
      " 11  nativity    344287 non-null  float64\n",
      " 12  educ99      344287 non-null  float64\n",
      " 13  classwkr    344287 non-null  int64  \n",
      " 14  wkswork1    344287 non-null  int64  \n",
      " 15  hrswork     344287 non-null  float64\n",
      " 16  uhrswork    344287 non-null  int64  \n",
      " 17  union       344287 non-null  float64\n",
      " 18  incwage     344287 non-null  float64\n",
      " 19  inclongj    344287 non-null  float64\n",
      " 20  srcearn     344287 non-null  float64\n",
      " 21  hisp        344287 non-null  int64  \n",
      " 22  annhrs      344287 non-null  int64  \n",
      " 23  incwageman  344287 non-null  float64\n",
      " 24  hrwage      344287 non-null  float64\n",
      " 25  perconexp   344287 non-null  float64\n",
      " 26  hdwfcoh     344287 non-null  int64  \n",
      " 27  industry    344287 non-null  int64  \n",
      " 28  occupation  344287 non-null  int64  \n",
      " 29  education   344287 non-null  int64  \n",
      "dtypes: float64(12), int64(18)\n",
      "memory usage: 78.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('new_data.csv')\n",
    "\n",
    "# Display basic info\n",
    "print(data.head())\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Details\n",
    "\n",
    "- **`sex`:** Gender of the individual\n",
    "  - `1` = Male\n",
    "  - `2` = Female\n",
    "\n",
    "- **`incwage`:** Wage and salary income (used as the target variable).\n",
    "\n",
    "- **`hrwage`:** Hourly wage.\n",
    "\n",
    "- **`incwageman`:** Manually Created INCWAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "\n",
    "# Replace 'incwage' with 'hrwage' if working with hourly wage\n",
    "X = data.drop(columns=['incwageman'])  \n",
    "y = data['incwageman']  # Target variable: wage and salary income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year          0\n",
      "hwtsupp       0\n",
      "region        0\n",
      "statefip      0\n",
      "metro         0\n",
      "pernum        0\n",
      "relate        0\n",
      "age           0\n",
      "sex           0\n",
      "race          0\n",
      "marst         0\n",
      "nativity      0\n",
      "educ99        0\n",
      "classwkr      0\n",
      "wkswork1      0\n",
      "hrswork       0\n",
      "uhrswork      0\n",
      "union         0\n",
      "incwage       0\n",
      "inclongj      0\n",
      "srcearn       0\n",
      "hisp          0\n",
      "annhrs        0\n",
      "hrwage        0\n",
      "perconexp     0\n",
      "hdwfcoh       0\n",
      "industry      0\n",
      "occupation    0\n",
      "education     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         14200.0\n",
       "1         17680.0\n",
       "2         28000.0\n",
       "3         27500.0\n",
       "4         17000.0\n",
       "           ...   \n",
       "344282    17000.0\n",
       "344283     3200.0\n",
       "344284    13000.0\n",
       "344285     8800.0\n",
       "344286    15000.0\n",
       "Name: incwageman, Length: 344287, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Parameters of Gradient Boosting\n",
    "\n",
    "## 1. **`n_estimators`**\n",
    "- **Definition**:\n",
    "  - This parameter specifies the **number of weak learners (trees)** to train in the ensemble.\n",
    "  - Each tree is added sequentially to minimize the loss function.\n",
    "- **Impact**:\n",
    "  - A higher value can improve accuracy but may increase training time and lead to overfitting.\n",
    "  - A lower value may lead to underfitting if the model complexity is insufficient.\n",
    "- **Default Value**: 100\n",
    "- **Guidelines for Tuning**:\n",
    "  - Start with `n_estimators=100` and increase it gradually if the model underfits.\n",
    "  - Use early stopping with cross-validation to avoid overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **`max_depth`**\n",
    "- **Definition**:\n",
    "  - This parameter determines the **maximum depth of each decision tree** in the ensemble.\n",
    "  - It controls the complexity of individual trees.\n",
    "- **Impact**:\n",
    "  - A larger value allows the trees to capture more complex patterns but can lead to overfitting.\n",
    "  - A smaller value restricts the complexity of the trees, reducing the risk of overfitting but may underfit the data.\n",
    "- **Default Value**: 3\n",
    "- **Guidelines for Tuning**:\n",
    "  - Use `max_depth=3` as a starting point.\n",
    "  - Increase it for complex datasets where deeper trees are required.\n",
    "  - Decrease it for small datasets or when overfitting is observed.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **`random_state`**\n",
    "- **Definition**:\n",
    "  - This parameter is used to **control randomness** in the model training process.\n",
    "  - It ensures reproducibility by fixing the random seed for processes like data splitting and model initialization.\n",
    "- **Impact**:\n",
    "  - Using the same `random_state` across experiments ensures that results are consistent.\n",
    "- **Default Value**: `None` (random seed changes with each execution)\n",
    "- **Guidelines for Tuning**:\n",
    "  - Use a fixed value (e.g., `random_state=42`) during model development and experimentation to ensure reproducibility.\n",
    "  - It does not affect the model's predictive power but ensures consistency in results.\n",
    "\n",
    "---\n",
    "\n",
    "# Summary Table\n",
    "\n",
    "| Parameter       | Role                                                                 | Default Value | Guidelines for Tuning                                    |\n",
    "|------------------|----------------------------------------------------------------------|---------------|---------------------------------------------------------|\n",
    "| `n_estimators`  | Number of weak learners (trees) in the ensemble                      | 100           | Increase to improve accuracy; use early stopping to avoid overfitting. |\n",
    "| `max_depth`     | Maximum depth of each decision tree                                  | 3             | Start with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Prediction for Males: 47420.44\n",
      "Average Prediction for Females: 31373.04\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "# print(\"Training Gradient Boosting Regressor...\")\n",
    "gb_model.fit(X_train, y_train)\n",
    "# print(\"Model Training Complete!\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Add gender back to X_test for grouping predictions\n",
    "X_test['gender'] = X_test['sex']  # Ensure 'sex' exists in X_test\n",
    "\n",
    "# Separate predictions for males and females\n",
    "X_test['predictions'] = y_pred\n",
    "male_predictions = X_test[X_test['gender'] == 1]['predictions']\n",
    "female_predictions = X_test[X_test['gender'] == 2]['predictions']\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Average Prediction for Males: {male_predictions.mean():.2f}\")\n",
    "print(f\"Average Prediction for Females: {female_predictions.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>hwtsupp</th>\n",
       "      <th>region</th>\n",
       "      <th>statefip</th>\n",
       "      <th>metro</th>\n",
       "      <th>pernum</th>\n",
       "      <th>relate</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>hisp</th>\n",
       "      <th>annhrs</th>\n",
       "      <th>hrwage</th>\n",
       "      <th>perconexp</th>\n",
       "      <th>hdwfcoh</th>\n",
       "      <th>industry</th>\n",
       "      <th>occupation</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243198</th>\n",
       "      <td>2007</td>\n",
       "      <td>1927.300049</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2080</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>94.727997</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>31519.557935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286308</th>\n",
       "      <td>2011</td>\n",
       "      <td>780.270020</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2040</td>\n",
       "      <td>17.156862</td>\n",
       "      <td>101.653999</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>34986.393032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22328</th>\n",
       "      <td>1999</td>\n",
       "      <td>3826.449951</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4160</td>\n",
       "      <td>12.019231</td>\n",
       "      <td>79.933998</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50032.343901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29413</th>\n",
       "      <td>2011</td>\n",
       "      <td>771.169983</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>19.230770</td>\n",
       "      <td>101.653999</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50032.343901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168004</th>\n",
       "      <td>1990</td>\n",
       "      <td>688.840027</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>64.639999</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44215.505524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307637</th>\n",
       "      <td>1999</td>\n",
       "      <td>365.040009</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>79.933998</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>44215.505524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272551</th>\n",
       "      <td>2011</td>\n",
       "      <td>826.880005</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>11.923077</td>\n",
       "      <td>101.653999</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15849.821193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267178</th>\n",
       "      <td>2009</td>\n",
       "      <td>1756.540039</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1040</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>100.063004</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3247.570936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77239</th>\n",
       "      <td>1990</td>\n",
       "      <td>376.119995</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>29.004168</td>\n",
       "      <td>64.639999</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14112.653984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330738</th>\n",
       "      <td>2013</td>\n",
       "      <td>1706.400024</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1820</td>\n",
       "      <td>9.890110</td>\n",
       "      <td>106.009003</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>17869.192158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68858 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year      hwtsupp  region  statefip  metro  pernum  relate  age  sex  \\\n",
       "243198  2007  1927.300049       3         6    3.0       1     101   47    2   \n",
       "286308  2011   780.270020       1        27    1.0       1     101   28    2   \n",
       "22328   1999  3826.449951       3         6    2.0       2     201   45    1   \n",
       "29413   2011   771.169983       1        27    1.0       1     101   49    1   \n",
       "168004  1990   688.840027       0        44    3.0       1     101   31    1   \n",
       "...      ...          ...     ...       ...    ...     ...     ...  ...  ...   \n",
       "307637  1999   365.040009       1        38    1.0       2     201   41    2   \n",
       "272551  2011   826.880005       1        27    3.0       2     201   44    2   \n",
       "267178  2009  1756.540039       2        48    3.0       1     101   49    2   \n",
       "77239   1990   376.119995       0        50    1.0       1     101   59    1   \n",
       "330738  2013  1706.400024       0        36    2.0       1     101   35    2   \n",
       "\n",
       "        race  ...  hisp  annhrs     hrwage   perconexp  hdwfcoh  industry  \\\n",
       "243198     2  ...     0    2080  15.384615   94.727997        1        14   \n",
       "286308     0  ...     0    2040  17.156862  101.653999        1        10   \n",
       "22328      0  ...     0    4160  12.019231   79.933998        1        12   \n",
       "29413      0  ...     0    2600  19.230770  101.653999        1         3   \n",
       "168004     0  ...     0    2600  16.923077   64.639999        1        10   \n",
       "...      ...  ...   ...     ...        ...         ...      ...       ...   \n",
       "307637     2  ...     0    1600  27.500000   79.933998        1        13   \n",
       "272551     0  ...     0    1300  11.923077  101.653999        1         7   \n",
       "267178     3  ...     1    1040   3.000000  100.063004        1        10   \n",
       "77239      0  ...     0     480  29.004168   64.639999        1         4   \n",
       "330738     3  ...     1    1820   9.890110  106.009003        1        12   \n",
       "\n",
       "        occupation  education  gender   predictions  \n",
       "243198          17          5       2  31519.557935  \n",
       "286308          14          5       2  34986.393032  \n",
       "22328           17          3       1  50032.343901  \n",
       "29413           19          5       1  50032.343901  \n",
       "168004           4          2       1  44215.505524  \n",
       "...            ...        ...     ...           ...  \n",
       "307637           8          2       2  44215.505524  \n",
       "272551          16          5       2  15849.821193  \n",
       "267178          14          5       2   3247.570936  \n",
       "77239           20          5       1  14112.653984  \n",
       "330738          12          5       2  17869.192158  \n",
       "\n",
       "[68858 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_alternated = X_test.copy()\n",
    "\n",
    "X_test_alternated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>hwtsupp</th>\n",
       "      <th>region</th>\n",
       "      <th>statefip</th>\n",
       "      <th>metro</th>\n",
       "      <th>pernum</th>\n",
       "      <th>relate</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>hisp</th>\n",
       "      <th>annhrs</th>\n",
       "      <th>hrwage</th>\n",
       "      <th>perconexp</th>\n",
       "      <th>hdwfcoh</th>\n",
       "      <th>industry</th>\n",
       "      <th>occupation</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243198</th>\n",
       "      <td>2007</td>\n",
       "      <td>1927.300049</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2080</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>94.727997</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>31519.557935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286308</th>\n",
       "      <td>2011</td>\n",
       "      <td>780.270020</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2040</td>\n",
       "      <td>17.156862</td>\n",
       "      <td>101.653999</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>34986.393032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22328</th>\n",
       "      <td>1999</td>\n",
       "      <td>3826.449951</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4160</td>\n",
       "      <td>12.019231</td>\n",
       "      <td>79.933998</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50032.343901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29413</th>\n",
       "      <td>2011</td>\n",
       "      <td>771.169983</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>19.230770</td>\n",
       "      <td>101.653999</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>50032.343901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168004</th>\n",
       "      <td>1990</td>\n",
       "      <td>688.840027</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>64.639999</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>44215.505524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307637</th>\n",
       "      <td>1999</td>\n",
       "      <td>365.040009</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>79.933998</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>44215.505524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272551</th>\n",
       "      <td>2011</td>\n",
       "      <td>826.880005</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>11.923077</td>\n",
       "      <td>101.653999</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15849.821193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267178</th>\n",
       "      <td>2009</td>\n",
       "      <td>1756.540039</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1040</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>100.063004</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3247.570936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77239</th>\n",
       "      <td>1990</td>\n",
       "      <td>376.119995</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>29.004168</td>\n",
       "      <td>64.639999</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14112.653984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330738</th>\n",
       "      <td>2013</td>\n",
       "      <td>1706.400024</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1820</td>\n",
       "      <td>9.890110</td>\n",
       "      <td>106.009003</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>17869.192158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68858 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year      hwtsupp  region  statefip  metro  pernum  relate  age  sex  \\\n",
       "243198  2007  1927.300049       3         6    3.0       1     101   47    1   \n",
       "286308  2011   780.270020       1        27    1.0       1     101   28    1   \n",
       "22328   1999  3826.449951       3         6    2.0       2     201   45    2   \n",
       "29413   2011   771.169983       1        27    1.0       1     101   49    2   \n",
       "168004  1990   688.840027       0        44    3.0       1     101   31    2   \n",
       "...      ...          ...     ...       ...    ...     ...     ...  ...  ...   \n",
       "307637  1999   365.040009       1        38    1.0       2     201   41    1   \n",
       "272551  2011   826.880005       1        27    3.0       2     201   44    1   \n",
       "267178  2009  1756.540039       2        48    3.0       1     101   49    1   \n",
       "77239   1990   376.119995       0        50    1.0       1     101   59    2   \n",
       "330738  2013  1706.400024       0        36    2.0       1     101   35    1   \n",
       "\n",
       "        race  ...  hisp  annhrs     hrwage   perconexp  hdwfcoh  industry  \\\n",
       "243198     2  ...     0    2080  15.384615   94.727997        1        14   \n",
       "286308     0  ...     0    2040  17.156862  101.653999        1        10   \n",
       "22328      0  ...     0    4160  12.019231   79.933998        1        12   \n",
       "29413      0  ...     0    2600  19.230770  101.653999        1         3   \n",
       "168004     0  ...     0    2600  16.923077   64.639999        1        10   \n",
       "...      ...  ...   ...     ...        ...         ...      ...       ...   \n",
       "307637     2  ...     0    1600  27.500000   79.933998        1        13   \n",
       "272551     0  ...     0    1300  11.923077  101.653999        1         7   \n",
       "267178     3  ...     1    1040   3.000000  100.063004        1        10   \n",
       "77239      0  ...     0     480  29.004168   64.639999        1         4   \n",
       "330738     3  ...     1    1820   9.890110  106.009003        1        12   \n",
       "\n",
       "        occupation  education  gender   predictions  \n",
       "243198          17          5       2  31519.557935  \n",
       "286308          14          5       2  34986.393032  \n",
       "22328           17          3       1  50032.343901  \n",
       "29413           19          5       1  50032.343901  \n",
       "168004           4          2       1  44215.505524  \n",
       "...            ...        ...     ...           ...  \n",
       "307637           8          2       2  44215.505524  \n",
       "272551          16          5       2  15849.821193  \n",
       "267178          14          5       2   3247.570936  \n",
       "77239           20          5       1  14112.653984  \n",
       "330738          12          5       2  17869.192158  \n",
       "\n",
       "[68858 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_alternated['sex'] = np.where(X_test_alternated['sex'] == 1, 2, 1)\n",
    "X_test_alternated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>hwtsupp</th>\n",
       "      <th>region</th>\n",
       "      <th>statefip</th>\n",
       "      <th>metro</th>\n",
       "      <th>pernum</th>\n",
       "      <th>relate</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>inclongj</th>\n",
       "      <th>srcearn</th>\n",
       "      <th>hisp</th>\n",
       "      <th>annhrs</th>\n",
       "      <th>hrwage</th>\n",
       "      <th>perconexp</th>\n",
       "      <th>hdwfcoh</th>\n",
       "      <th>industry</th>\n",
       "      <th>occupation</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243198</th>\n",
       "      <td>2007</td>\n",
       "      <td>1927.300049</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2080</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>94.727997</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286308</th>\n",
       "      <td>2011</td>\n",
       "      <td>780.270020</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2040</td>\n",
       "      <td>17.156862</td>\n",
       "      <td>101.653999</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22328</th>\n",
       "      <td>1999</td>\n",
       "      <td>3826.449951</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4160</td>\n",
       "      <td>12.019231</td>\n",
       "      <td>79.933998</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29413</th>\n",
       "      <td>2011</td>\n",
       "      <td>771.169983</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>19.230770</td>\n",
       "      <td>101.653999</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168004</th>\n",
       "      <td>1990</td>\n",
       "      <td>688.840027</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>64.639999</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307637</th>\n",
       "      <td>1999</td>\n",
       "      <td>365.040009</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>79.933998</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272551</th>\n",
       "      <td>2011</td>\n",
       "      <td>826.880005</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>11.923077</td>\n",
       "      <td>101.653999</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267178</th>\n",
       "      <td>2009</td>\n",
       "      <td>1756.540039</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1040</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>100.063004</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77239</th>\n",
       "      <td>1990</td>\n",
       "      <td>376.119995</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13922.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>29.004168</td>\n",
       "      <td>64.639999</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330738</th>\n",
       "      <td>2013</td>\n",
       "      <td>1706.400024</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1820</td>\n",
       "      <td>9.890110</td>\n",
       "      <td>106.009003</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68858 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year      hwtsupp  region  statefip  metro  pernum  relate  age  sex  \\\n",
       "243198  2007  1927.300049       3         6    3.0       1     101   47    1   \n",
       "286308  2011   780.270020       1        27    1.0       1     101   28    1   \n",
       "22328   1999  3826.449951       3         6    2.0       2     201   45    2   \n",
       "29413   2011   771.169983       1        27    1.0       1     101   49    2   \n",
       "168004  1990   688.840027       0        44    3.0       1     101   31    2   \n",
       "...      ...          ...     ...       ...    ...     ...     ...  ...  ...   \n",
       "307637  1999   365.040009       1        38    1.0       2     201   41    1   \n",
       "272551  2011   826.880005       1        27    3.0       2     201   44    1   \n",
       "267178  2009  1756.540039       2        48    3.0       1     101   49    1   \n",
       "77239   1990   376.119995       0        50    1.0       1     101   59    2   \n",
       "330738  2013  1706.400024       0        36    2.0       1     101   35    1   \n",
       "\n",
       "        race  ...  inclongj  srcearn  hisp  annhrs     hrwage   perconexp  \\\n",
       "243198     2  ...   32000.0      1.0     0    2080  15.384615   94.727997   \n",
       "286308     0  ...   35000.0      1.0     0    2040  17.156862  101.653999   \n",
       "22328      0  ...   50000.0      1.0     0    4160  12.019231   79.933998   \n",
       "29413      0  ...   50000.0      1.0     0    2600  19.230770  101.653999   \n",
       "168004     0  ...   44000.0      1.0     0    2600  16.923077   64.639999   \n",
       "...      ...  ...       ...      ...   ...     ...        ...         ...   \n",
       "307637     2  ...   44000.0      1.0     0    1600  27.500000   79.933998   \n",
       "272551     0  ...   15500.0      1.0     0    1300  11.923077  101.653999   \n",
       "267178     3  ...    3120.0      1.0     1    1040   3.000000  100.063004   \n",
       "77239      0  ...   13922.0      1.0     0     480  29.004168   64.639999   \n",
       "330738     3  ...   18000.0      1.0     1    1820   9.890110  106.009003   \n",
       "\n",
       "        hdwfcoh  industry  occupation  education  \n",
       "243198        1        14          17          5  \n",
       "286308        1        10          14          5  \n",
       "22328         1        12          17          3  \n",
       "29413         1         3          19          5  \n",
       "168004        1        10           4          2  \n",
       "...         ...       ...         ...        ...  \n",
       "307637        1        13           8          2  \n",
       "272551        1         7          16          5  \n",
       "267178        1        10          14          5  \n",
       "77239         1         4          20          5  \n",
       "330738        1        12          12          5  \n",
       "\n",
       "[68858 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_columns = [col for col in X_train.columns]  # Ensure only training features are included\n",
    "X_test_alternated = X_test_alternated[feature_columns]\n",
    "\n",
    "X_test_alternated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the alternated dataset\n",
    "alternated_predictions = gb_model.predict(X_test_alternated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternated Average Prediction for Males: 31373.04\n",
      "Alternated Average Prediction for Females: 47420.44\n"
     ]
    }
   ],
   "source": [
    "# Add alternated predictions back to X_test for grouping\n",
    "X_test['alternated_predictions'] = alternated_predictions\n",
    "\n",
    "# Separate predictions for alternated males and females\n",
    "alternated_male_predictions = X_test[X_test['sex'] == 2]['alternated_predictions']\n",
    "alternated_female_predictions = X_test[X_test['sex'] == 1]['alternated_predictions']\n",
    "\n",
    "# Calculate averages\n",
    "alternated_male_avg = alternated_male_predictions.mean()\n",
    "alternated_female_avg = alternated_female_predictions.mean()\n",
    "\n",
    "# Print results\n",
    "print(f\"Alternated Average Prediction for Males: {alternated_male_avg:.2f}\")\n",
    "print(f\"Alternated Average Prediction for Females: {alternated_female_avg:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: 0.00000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate KL Divergence\n",
    "def calculate_kl_divergence(original_predictions, alternated_predictions):\n",
    "    epsilon = 1e-10  # Small value to avoid log(0) or division by zero\n",
    "    \n",
    "    # Stabilize softmax by subtracting the maximum value from predictions\n",
    "    original_predictions_stable = original_predictions - np.max(original_predictions)\n",
    "    alternated_predictions_stable = alternated_predictions - np.max(alternated_predictions)\n",
    "    \n",
    "    # Convert predictions to probabilities using stable softmax\n",
    "    original_probs = np.exp(original_predictions_stable) / (np.sum(np.exp(original_predictions_stable)) + epsilon)\n",
    "    alternated_probs = np.exp(alternated_predictions_stable) / (np.sum(np.exp(alternated_predictions_stable)) + epsilon)\n",
    "    \n",
    "    # Compute KL Divergence\n",
    "    kl_divergence = entropy(original_probs, alternated_probs)\n",
    "    return kl_divergence\n",
    "\n",
    "# Calculate KL Divergence\n",
    "kl_div = calculate_kl_divergence(y_pred, alternated_predictions)\n",
    "print(f\"KL Divergence: {kl_div:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance of 'sex': 0.00000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature importance of 'sex': {gb_model.feature_importances_[X_train.columns.get_loc('sex')]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance: {'year': 3.3103099185772797e-07, 'hwtsupp': 3.272647886703844e-05, 'region': 1.2205763818853972e-08, 'statefip': 8.525495822925723e-08, 'metro': 0.0, 'pernum': 0.0, 'relate': 0.0, 'age': 0.0, 'sex': 0.0, 'race': 3.0323378880385616e-07, 'marst': 0.0, 'classwkr': 0.0, 'wkswork1': 8.165390861120556e-08, 'hrswork': 1.8749157173127458e-08, 'uhrswork': 0.0, 'incwage': 0.9999658468403189, 'hisp': 7.893905163764646e-08, 'annhrs': 0.0, 'hrwage': 4.0408192516936715e-07, 'perconexp': 1.0164460009121556e-07, 'hdwfcoh': 0.0, 'industry': 0.0, 'occupation': 0.0, 'education': 9.88666869327195e-09}\n"
     ]
    }
   ],
   "source": [
    "feature_importance = gb_model.feature_importances_\n",
    "print(\"Feature Importance:\", dict(zip(X_train.columns, feature_importance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incwage       1.000000\n",
      "annhrs        0.336535\n",
      "uhrswork      0.303378\n",
      "year          0.280524\n",
      "perconexp     0.280087\n",
      "hrswork       0.239155\n",
      "wkswork1      0.190340\n",
      "age           0.122743\n",
      "hdwfcoh       0.091643\n",
      "metro         0.085873\n",
      "hrwage        0.042001\n",
      "industry      0.025416\n",
      "hwtsupp       0.021327\n",
      "classwkr      0.007701\n",
      "region       -0.019709\n",
      "statefip     -0.027490\n",
      "relate       -0.066513\n",
      "pernum       -0.074498\n",
      "race         -0.079119\n",
      "hisp         -0.084129\n",
      "marst        -0.086230\n",
      "sex          -0.179722\n",
      "occupation   -0.259114\n",
      "education    -0.270863\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation = X_train.corrwith(y_train)  # Correlation of each feature with target\n",
    "print(correlation.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between 'sex' and 'incwageman': -0.17972\n"
     ]
    }
   ],
   "source": [
    "corr_value = X_train['sex'].corr(y_train)\n",
    "print(f\"Correlation between 'sex' and 'incwageman': {corr_value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance of 'sex': 0.00000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature importance of 'sex': {gb_model.feature_importances_[X_train.columns.get_loc('sex')]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature    Importance\n",
      "15     incwage  9.999658e-01\n",
      "1      hwtsupp  3.272648e-05\n",
      "18      hrwage  4.040819e-07\n",
      "0         year  3.310310e-07\n",
      "9         race  3.032338e-07\n",
      "19   perconexp  1.016446e-07\n",
      "3     statefip  8.525496e-08\n",
      "12    wkswork1  8.165391e-08\n",
      "16        hisp  7.893905e-08\n",
      "13     hrswork  1.874916e-08\n",
      "2       region  1.220576e-08\n",
      "23   education  9.886669e-09\n",
      "8          sex  0.000000e+00\n",
      "7          age  0.000000e+00\n",
      "10       marst  0.000000e+00\n",
      "11    classwkr  0.000000e+00\n",
      "6       relate  0.000000e+00\n",
      "14    uhrswork  0.000000e+00\n",
      "5       pernum  0.000000e+00\n",
      "17      annhrs  0.000000e+00\n",
      "4        metro  0.000000e+00\n",
      "20     hdwfcoh  0.000000e+00\n",
      "21    industry  0.000000e+00\n",
      "22  occupation  0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': gb_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Prediction for Males: 47806.85\n",
      "Average Prediction for Females: 31453.21\n",
      "Alternated Average Prediction for Males: 31453.21\n",
      "Alternated Average Prediction for Females: 47806.85\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target with 'sex' as the only feature\n",
    "X = data[['sex']]  # Feature: Gender\n",
    "y = data['incwageman']  # Target: Wage and salary income\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Separate predictions for males and females\n",
    "male_predictions = y_pred[X_test['sex'] == 1]  # Predictions for males\n",
    "female_predictions = y_pred[X_test['sex'] == 2]  # Predictions for females\n",
    "\n",
    "# Calculate average predictions\n",
    "male_avg = male_predictions.mean()\n",
    "female_avg = female_predictions.mean()\n",
    "\n",
    "print(f\"Average Prediction for Males: {male_avg:.2f}\")\n",
    "print(f\"Average Prediction for Females: {female_avg:.2f}\")\n",
    "\n",
    "# Alternate gender and predict\n",
    "X_test_alternated = X_test.copy()\n",
    "X_test_alternated['sex'] = np.where(X_test['sex'] == 1, 2, 1)  # Flip genders\n",
    "alternated_predictions = gb_model.predict(X_test_alternated)\n",
    "\n",
    "# Separate alternated predictions for males and females\n",
    "alternated_male_predictions = alternated_predictions[X_test['sex'] == 1]  # Alternated males (original females)\n",
    "alternated_female_predictions = alternated_predictions[X_test['sex'] == 2]  # Alternated females (original males)\n",
    "\n",
    "# Calculate alternated average predictions\n",
    "alternated_male_avg = alternated_male_predictions.mean()\n",
    "alternated_female_avg = alternated_female_predictions.mean()\n",
    "\n",
    "print(f\"Alternated Average Prediction for Males: {alternated_male_avg:.2f}\")\n",
    "print(f\"Alternated Average Prediction for Females: {alternated_female_avg:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "1    47729.860941\n",
      "2    31436.945960\n",
      "Name: incwageman, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Average income by gender\n",
    "avg_income_by_gender = data.groupby('sex')['incwageman'].mean()\n",
    "print(avg_income_by_gender)\n",
    "\n",
    "# Income distribution by gender\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x=data['sex'], y=data['incwageman'])\n",
    "plt.title(\"Income Distribution by Gender\")\n",
    "plt.xticks(ticks=[0, 1], labels=['Male', 'Female'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msai339",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
